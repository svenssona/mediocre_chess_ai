{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d28e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1942f53",
   "metadata": {},
   "source": [
    "# Hemmaplan\n",
    " > This is where we train our models, using our \"Home Court\" advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b3bd0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ChessValueDataset(Dataset):\n",
    "    \"\"\"Chess games dataset\"\"\"\n",
    "    def __init__(self):\n",
    "        dat = np.load(\"processed/dataset_1k.npz\")\n",
    "        self.X = dat[\"arr_0\"]\n",
    "        self.Y = dat[\"arr_1\"]\n",
    "        print(\"loaded\", self.X.shape, self.Y.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded (1140, 5, 8, 8) (1140,)\n"
     ]
    }
   ],
   "source": [
    "chess_dataset = ChessValueDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a14baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides the data into mini batches.\n",
    "train_loader = torch.utils.data.DataLoader(chess_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596a41d",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "> Convolutionl deep neural network that trains on our chess data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # First convolutional layer taking in the 5 chanels for board state,\n",
    "        # outputting 16 convolutional features, with a square kernel size of 3\n",
    "        self.a1 = nn.Conv2d(5, 16, kernel_size=3, padding=1)                 \n",
    "        self.a2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.a3 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "\n",
    "        self.b1 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.b2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.b3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "\n",
    "        self.c1 = nn.Conv2d(64, 64, kernel_size=2, padding=1)\n",
    "        self.c2 = nn.Conv2d(64, 64, kernel_size=2, padding=1)\n",
    "        self.c3 = nn.Conv2d(64, 128, kernel_size=2, stride=2)\n",
    "\n",
    "        self.d1 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "        self.d2 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "        self.d3 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "\n",
    "        self.last = nn.Linear(128, 1)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "        # Pass data through the first convolutional layer\n",
    "        # and apply the rectified-linear activation function over x\n",
    "        x = F.relu(self.a1(x))\n",
    "        x = F.relu(self.a2(x))\n",
    "        x = F.relu(self.a3(x))\n",
    "\n",
    "        # Run max pooling over x to down-sample with kernel size of 2\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # 4x4\n",
    "        x = F.relu(self.b1(x))\n",
    "        x = F.relu(self.b2(x))\n",
    "        x = F.relu(self.b3(x))\n",
    "\n",
    "        # 2x2 \n",
    "        x = F.relu(self.c1(x))\n",
    "        x = F.relu(self.c2(x))\n",
    "        x = F.relu(self.c3(x))\n",
    "\n",
    "        # 1x128\n",
    "\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        x = F.relu(self.d3(x))\n",
    "\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.last(x)\n",
    "\n",
    "        # value output\n",
    "        return torch.tanh(x)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d5d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/fastai2/lib/python3.8/site-packages/torch/autograd/__init__.py:147: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Creates a Neural Network according from our Net class with Adam as optimizer.\n",
    "model = Net()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Use choose between cpu and cuda\n",
    "device = \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    model.cuda()\n",
    "\n",
    "# Sets the model in training mode\n",
    "model.train();\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target.unsqueeze(-1)\n",
    "        data = data.float()\n",
    "        target = target.float()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Resets the gradients in the optimizer to zero.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass data through our model.\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss between our outputs and targets.\n",
    "        loss = criterion(output, target)\n",
    "        # Computes the gradient of current tensor w.r.t graph leaves. \n",
    "        loss.backward() \n",
    "        # Performs a parameter update to our model.\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 200 == 199:    # print every 199 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "# last model trained for 10 epochs on 10M data 0.547 loss\n",
    "#torch.save(model.state_dict(), \"nets/value_gen2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_state.ipynb.\n",
      "Converted 01_generate_training_set.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted 03_play.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912f534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

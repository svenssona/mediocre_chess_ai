# AUTOGENERATED! DO NOT EDIT! File to edit: 00_State.ipynb (unless otherwise specified).

__all__ = ['State', 'get_dataset', 'ChessValueDataset', 'chess_dataset', 'train_loader', 'Valuator', 'explore_leaves',
           'computer_move', 'move', 's', 'v', 'quit']

# Cell
class State(object):
    def __init__(self, board=None):
        if board is None:
            self.board = chess.Board()
        else:
            self.board = board

    def shredder_fen_to_vec(x):
        pass

    def serialize(self):
        "numericalize current board states"
        assert self.board.is_valid()

        # Init board state.
        bstate = np.zeros(64, np.uint8)
        for i in range(64):
            pp = self.board.piece_at(i)
            if pp is not None:
                # Assigns a value representing the pieces (capitalized letters are white pieces).
                bstate[i] = {"P": 1, "N": 2, "B": 3, "R": 4, "Q": 5, "K": 6, \
                             "p": 9, "n": 10, "b": 11, "r": 12, "q": 13, "k": 14}[pp.symbol()] # lowercase black

        # Special board states 7,8 and 15.
        # Determine if we can castle on white.
        if self.board.has_queenside_castling_rights(chess.WHITE):
            assert bstate[0] == 4
            bstate[0] = 7
        if self.board.has_kingside_castling_rights(chess.WHITE):
            assert bstate[7] == 4
            bstate[7] = 7

        # Determine if we can castle on black.
        if self.board.has_queenside_castling_rights(chess.BLACK):
            assert bstate[56] == 12
            bstate[56] = 15
        if self.board.has_kingside_castling_rights(chess.BLACK):
            assert bstate[63] == 12
            bstate[63] = 15

        # Gives the potential en passant square.
        if self.board.ep_square is not None:
            assert bstate[self.board.ep_square] == 0
            bstate[self.board.ep_square] = 8

        # Reshapes the board state to a matrix.
        bstate = bstate.reshape(8,8)

        # 320 bits according to readme.
        state = np.zeros((5,8,8), np.uint8)

        # 0-3 to binary.
        state[0] = (bstate>>3)&1
        state[1] = (bstate>>2)&1
        state[2] = (bstate>>1)&1
        state[3] = (bstate>>0)&1

        # 4th column is who's turn it is.
        state[4] = (self.board.turn*1.0)

        return state

    def edges(self):
        return list(self.board.legal_moves)

    # Value function all postions are equal.
    def value(self):
        # TODO: add neural net here
        return 1

# Cell
def get_dataset(num_samples):
    # Initialize variables for storing board states and results.
    X,Y = [], []
    gn = 0

    # Value from each match depending on outcome.
    values = {'1/2-1/2': 0, '0-1': -1, '1-0': 1}

    for fn in os.listdir("data"):
        # pgn files in this data folder
        pgn = open(os.path.join("data", fn))
        while 1:
            game = chess.pgn.read_game(pgn)
            if game is None:
                break
            # Gets the result from the game.
            res = game.headers["Result"]
            if res not in values:
                continue
            value = values[res]

            # Plays the next move .
            board = game.board()
            for i,move in enumerate(game.mainline_moves()):
                board.push(move)
                ser = State(board).serialize()
                X.append(ser)
                Y.append(value)
            print("parsing game %d, got %d examples" % (gn, len(X)))

            # Cancel if we got enough examples.
            if num_samples is not None and len(X) > num_samples:
                return X,Y
            gn +=1
    # Convert to numpy arrays
    X = np.array(X)
    Y = np.array(Y)
    return X,Y

# Cell
class ChessValueDataset(Dataset):
    """Chess games dataset"""
    def __init__(self):
        dat = np.load("processed/dataset_1k.npz")
        self.X = dat["arr_0"]
        self.Y = dat["arr_1"]
        print("loaded", self.X.shape, self.Y.shape)

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        return (self.X[idx], self.Y[idx])

# Cell
chess_dataset = ChessValueDataset()

# Cell
# Divides the data into mini batches.
train_loader = torch.utils.data.DataLoader(chess_dataset, batch_size=1024, shuffle=True)

# Cell
if __name__ == "__main__":
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()

            # First convolutional layer taking in the 5 chanels for board state,
            # outputting 16 convolutional features, with a square kernel size of 3
            self.a1 = nn.Conv2d(5, 16, kernel_size=3, padding=1)
            self.a2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)
            self.a3 = nn.Conv2d(16, 32, kernel_size=3, stride=2)

            self.b1 = nn.Conv2d(32, 32, kernel_size=3, padding=1)
            self.b2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)
            self.b3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)

            self.c1 = nn.Conv2d(64, 64, kernel_size=2, padding=1)
            self.c2 = nn.Conv2d(64, 64, kernel_size=2, padding=1)
            self.c3 = nn.Conv2d(64, 128, kernel_size=2, stride=2)

            self.d1 = nn.Conv2d(128, 128, kernel_size=1)
            self.d2 = nn.Conv2d(128, 128, kernel_size=1)
            self.d3 = nn.Conv2d(128, 128, kernel_size=1)

            self.last = nn.Linear(128, 1)

        # x represents our data
        def forward(self, x):
            # Pass data through the first convolutional layer
            # and apply the rectified-linear activation function over x
            x = F.relu(self.a1(x))
            x = F.relu(self.a2(x))
            x = F.relu(self.a3(x))

            # Run max pooling over x to down-sample with kernel size of 2
            # x = F.max_pool2d(x, 2)

            # 4x4
            x = F.relu(self.b1(x))
            x = F.relu(self.b2(x))
            x = F.relu(self.b3(x))

            # 2x2
            x = F.relu(self.c1(x))
            x = F.relu(self.c2(x))
            x = F.relu(self.c3(x))

            # 1x128

            x = F.relu(self.d1(x))
            x = F.relu(self.d2(x))
            x = F.relu(self.d3(x))

            x = x.view(-1, 128)
            x = self.last(x)

            # value output
            return torch.tanh(x)

    # Creates a Neural Network according from our Net class with Adam as optimizer.
    model = Net()
    optimizer = torch.optim.Adam(model.parameters())

    # Use choose between cpu and cuda
    device = "cuda"
    if device == "cuda":
        model.cuda()

    # Sets the model in training mode
    model.train();

    criterion = nn.MSELoss()

    for epoch in range(10): # loop over the dataset multiple times
        running_loss = 0.0
        for batch_idx, (data, target) in enumerate(train_loader):
            target = target.unsqueeze(-1)
            data = data.float()
            target = target.float()
            data, target = data.to(device), target.to(device)

            # Resets the gradients in the optimizer to zero.
            optimizer.zero_grad()

            # Pass data through our model.
            output = model(data)

            # Calculate loss between our outputs and targets.
            loss = criterion(output, target)
            # Computes the gradient of current tensor w.r.t graph leaves.
            loss.backward()
            # Performs a parameter update to our model.
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if batch_idx % 200 == 199:    # print every 199 mini-batches
                print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 200))
                running_loss = 0.0


    print('Finished Training')
    # last model trained for 10 epochs on 10M data 0.547 loss
    #torch.save(model.state_dict(), "nets/value_gen2.pth")

# Cell
class Valuator(object):
    """Valuates a given board state using a trained neural network"""
    def __init__(self):
        self.model = Net()
        self.param = torch.load("nets/value.pth", map_location=lambda storage, loc: storage)
        self.model.load_state_dict(self.param)

    def __call__(self, s):
        brd = s.serialize()[None]
        output = self.model(torch.tensor(brd).float())
        return float(output.data)

def explore_leaves(s, v):
    ret = []
    for mv in s.edges():
        s.board.push(mv)
        ret.append((v(s), mv))
        s.board.pop()
    return ret

# Chess board and "engine".
s = State()
v = Valuator()

def computer_move():
    moves = sorted(explore_leaves(s, v), key=lambda x: x[0], reverse=s.board.turn)
    print("Computer moves:", moves[0])
    s.board.push(moves[0][1])

def move():
    if not s.board.is_game_over():
        human_move = input("Next move: ")
    if chess.Move.from_uci(human_move) in s.board.legal_moves:
        print("Human moves:", human_move)
        s.board.push_san(human_move)
        computer_move()
    else:
        print("Illegal Move, try again.")

# Cell
if __name__ == "__main__":
    # Plays chess with it self.
    while not s.board.is_game_over():
        display(s.board)
        computer_move()
    print(s.board.result())

# Cell
quit = False
while not s.board.is_game_over() and not quit:
    try:
        display(s.board)
        move()
    except KeyboardInterrupt:
        print("User quit")
        quit = True